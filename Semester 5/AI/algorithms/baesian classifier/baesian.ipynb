{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cbfc9b",
   "metadata": {},
   "source": [
    "# Bayesian Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2266740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b04e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a small test dataset\n",
    "data = {\n",
    "    'Toothache':    [1, 0, 1, 0, 1, 0],\n",
    "    'Cavity':       [1, 1, 0, 0, 1, 0],\n",
    "    'VisitDentist': [1, 0, 1, 0, 1, 0]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a14420bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "For data [[1, 1], [0, 1]] Predictions: [1 0]\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "X = df[['Toothache', 'Cavity']]\n",
    "y = df['VisitDentist']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Bayesian classifier\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"For data\", X_test.values.tolist(), \"Predictions:\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14ebf007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sample: ['Sunny', 'Cool']\n",
      "Predicted Class: Yes\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Sample dataset (Outlook, Temperature, PlayTennis)\n",
    "# Features: Outlook, Temp\n",
    "# Label: Play (Yes/No)\n",
    "dataset = [\n",
    "    ['Sunny', 'Hot', 'No'],\n",
    "    ['Sunny', 'Hot', 'No'],\n",
    "    ['Overcast', 'Hot', 'Yes'],\n",
    "    ['Rain', 'Mild', 'Yes'],\n",
    "    ['Rain', 'Cool', 'Yes'],\n",
    "    ['Rain', 'Cool', 'No'],\n",
    "    ['Overcast', 'Cool', 'Yes'],\n",
    "    ['Sunny', 'Mild', 'No'],\n",
    "    ['Sunny', 'Cool', 'Yes'],\n",
    "    ['Rain', 'Mild', 'Yes'],\n",
    "    ['Sunny', 'Mild', 'Yes'],\n",
    "    ['Overcast', 'Mild', 'Yes'],\n",
    "    ['Overcast', 'Hot', 'Yes'],\n",
    "    ['Rain', 'Mild', 'No']\n",
    "]\n",
    "\n",
    "# Train function\n",
    "def train_naive_bayes(data):\n",
    "    label_counts = {}\n",
    "    feature_counts = {}\n",
    "\n",
    "    for row in data:\n",
    "        outlook, temp, label = row\n",
    "\n",
    "        # Count labels\n",
    "        label_counts[label] = label_counts.get(label, 0) + 1\n",
    "\n",
    "        # Count features conditional on labels\n",
    "        if label not in feature_counts:\n",
    "            feature_counts[label] = {\"Outlook\": {}, \"Temp\": {}}\n",
    "\n",
    "        feature_counts[label][\"Outlook\"][outlook] = feature_counts[label][\"Outlook\"].get(outlook, 0) + 1\n",
    "        feature_counts[label][\"Temp\"][temp] = feature_counts[label][\"Temp\"].get(temp, 0) + 1\n",
    "\n",
    "    return label_counts, feature_counts\n",
    "\n",
    "\n",
    "# Predict function\n",
    "def predict_naive_bayes(x, label_counts, feature_counts):\n",
    "    total = sum(label_counts.values())\n",
    "    probs = {}\n",
    "\n",
    "    for label in label_counts:\n",
    "        # Prior probability\n",
    "        probs[label] = label_counts[label] / total\n",
    "\n",
    "        # Likelihood (multiply conditional probabilities)\n",
    "        for i, feature in enumerate([\"Outlook\", \"Temp\"]):\n",
    "            value = x[i]\n",
    "            count = feature_counts[label][feature].get(value, 0)\n",
    "            probs[label] *= (count + 1) / (label_counts[label] + len(feature_counts[label][feature]))  # Laplace smoothing\n",
    "\n",
    "    return max(probs, key=probs.get)\n",
    "\n",
    "\n",
    "# Train model\n",
    "label_counts, feature_counts = train_naive_bayes(dataset)\n",
    "\n",
    "# Test prediction\n",
    "test_sample = ['Sunny', 'Cool']  # Outlook=Sunny, Temp=Cool\n",
    "prediction = predict_naive_bayes(test_sample, label_counts, feature_counts)\n",
    "\n",
    "print(\"Test Sample:\", test_sample)\n",
    "print(\"Predicted Class:\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
